{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1ffe2c8",
   "metadata": {},
   "source": [
    "#### Getting started With Langchain And Open AI\n",
    "\n",
    "In this quickstart we'll see how to:\n",
    "\n",
    "- Get setup with LangChain, LangSmith and LangServe\n",
    "- Use the most basic and common components of LangChain: prompt templates, models, and output parsers.\n",
    "- Build a simple application with LangChain\n",
    "- Trace your application with LangSmith\n",
    "- Serve your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "374720bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "## Langsmith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2da41438",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nikki\\LangChain\\Lenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profile={'max_input_tokens': 128000, 'max_output_tokens': 16384, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True} client=<openai.resources.chat.completions.completions.Completions object at 0x000001D93AC77280> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001D95566D6C0> root_client=<openai.OpenAI object at 0x000001D9540A7AC0> root_async_client=<openai.AsyncOpenAI object at 0x000001D95566D630> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********') stream_usage=True\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87954876",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input and get response form LLM\n",
    "\n",
    "result=llm.invoke(\"What is generative AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41bd4d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Generative AI refers to a class of artificial intelligence techniques that focuses on creating new content, whether it's text, images, audio, or other forms of data. Unlike traditional AI, which often focuses on classifying or predicting based on existing data, generative AI models can produce novel outputs that mimic the qualities of the input data they were trained on.\\n\\nKey examples of generative AI include:\\n\\n1. **Generative Adversarial Networks (GANs):** These involve two neural networks, a generator and a discriminator, that are trained together. The generator creates new data instances, while the discriminator evaluates them. This process continues until the generator produces outputs that are indistinguishable from real data.\\n\\n2. **Variational Autoencoders (VAEs):** These models are used to generate new data by learning a latent space representation of the data. VAEs aim to learn an efficient way to encode input data into a lower-dimensional space and then decode it back to the original space.\\n\\n3. **Large Language Models (LLMs):** These models, like OpenAI's GPT-3 and GPT-4, are capable of generating coherent and contextually relevant text based on input prompts. They are trained on vast amounts of text data and use deep learning techniques to predict the next word in a sentence.\\n\\n4. **Text-to-Image Models:** These models, such as OpenAI's DALL-E, generate images from text descriptions. They use a combination of natural language processing and computer vision to create visual content that matches the input text.\\n\\nGenerative AI has many applications, including in art and design, content creation, entertainment, and more. However, it also raises questions about ethical use and the potential for misuse, such as generating misleading or harmful content.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 353, 'prompt_tokens': 13, 'total_tokens': 366, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_deacdd5f6f', 'id': 'chatcmpl-Cyc0gPWLJBCoB14OwKDJ9Ux5q9GRN', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019bc67f-d563-7fe3-9885-78a255961af2-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 13, 'output_tokens': 353, 'total_tokens': 366, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b335bda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
