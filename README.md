# ğŸš€ Generative AI & RAG with LangChain 1.x

This repository contains **end-to-end implementations of Generative AI and Retrieval-Augmented Generation (RAG)** systems built using **LangChain 1.x**, following the **modern runnable-based pipeline approach** instead of deprecated chain abstractions.

The project demonstrates a complete real-world GenAI workflow â€” from **data ingestion** to **embeddings**, **vector stores**, **retrievers**, and **context-aware LLM responses**, using both **OpenAI** and **open-source models (Ollama, HuggingFace)**.

---

## ğŸ§  What You Will Learn

- Modern **LangChain 1.x runnable pipelines**
- Retrieval-Augmented Generation (RAG) from scratch
- Vector similarity search using FAISS & ChromaDB
- Context-aware LLM generation
- Working with both **cloud (OpenAI)** and **local (Ollama)** models
- Debuggable, production-ready GenAI architecture

---

## ğŸ› ï¸ Tech Stack

- **LangChain 1.x**
- **OpenAI (GPT-4 / GPT-4o-mini)**
- **Ollama (Local LLMs & Embeddings)**
- **FAISS & ChromaDB (Vector Stores)**
- **HuggingFace Embeddings**
- **Python**
- **Streamlit (Chat UI)**
- **LangSmith (Tracing & Observability)**

---

## âœ¨ Key Highlights

- âœ… Uses **pure LangChain 1.x runnable pipelines**
- âŒ No deprecated `langchain.chains` APIs
- âœ… Explicit retrieval and context injection
- âœ… Supports cloud + local LLMs
- âœ… Clean, debuggable, production-style code
- âœ… Streamlit-based chatbot interface
- âœ… LangSmith tracing for observability

ğŸ“Œ Author
Nikhil Shukla
Generative AI | LangChain | RAG | LLM Engineering


